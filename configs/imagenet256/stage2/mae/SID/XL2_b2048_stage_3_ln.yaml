dataset:
  type: imagenet
  transforms:
    type: imagenetDiT256x256

arch:
  stage: 2
  stage_1:
    target: rqvae.models.MAE.Stage1MAE
    params:
      ckpt_path: './ckpt_gcs/model_zoo/mae_base_256_ft_r'
      no_cls: true
      do_decoder_embed_in_encode: true
  connector:
    target: rqvae.models.connectors.ReshapeAndSplit_connector
    params:
      split: 1
      remove_cls: true
    ckpt_path: './ckpt_gcs/model_zoo/mae_base_256_ft_r/connector_512.pt'
  stage_2:
    target: rqvae.models.DiT.MultiStageDiT_Stage2
    params:
      # DiT B/1 Recipe
      input_size: 256
      num_classes: 1000
      learn_sigma: false
      in_channels: 2
      inflated_size: 256
      patch_sizes: [4, 16, 4]
      depths: [4, 24, 4]
      widths: [256, 1024, 256]
      num_heads: [16, 16, 16]
      mlp_ratios: [4, 4, 4]
      window_sizes: [4, 16, 4]
      cfg: 0.0
      noise_schedule: 'linear'
      inference_step: 250
      n_samples: 2
      do_beta_rescaling: true
      use_simple_diffusion: true
      use_loss_weighting: true
  checkpointing: false
  ema: 0.99

optimizer:
  # Original VQ-GAN: lr = 4.5e-06 * (batch size) -> 5.4e-5 for batch size 12
  type: adamw
  init_lr: 8.0e-4
  weight_decay: 0.0
  betas: [0.9, 0.95]
  max_gn: None
  amp: true
  warmup:
    epoch: 80
    multiplier: 1
    buffer_epoch: 0
    min_lr: 1.0e-4
    mode: fix
    start_from_zero: false

experiment:
  batch_size: 2
  accu_step: 2
  epochs: 80
  save_ckpt_freq: 40
  test_freq: 10
  amp: false
  actual_batch_size: 2048
