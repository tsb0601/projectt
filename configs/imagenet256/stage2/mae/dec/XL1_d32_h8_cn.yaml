dataset:
  type: imagenet
  transforms:
    type: imagenetDiT256x256

arch:
  stage: 2
  stage_1:
    target: rqvae.models.MAE.Stage1MAEwConvNextDCAE
    params:
      ckpt_path: './ckpt_gcs/model_zoo/mae_base_256_d32_h8'
      no_cls: true
      do_decoder_embed_in_encode: true
      up_layers_channels: [128, 256,768]
      down_layers_channels: [256,128, 32]
      down_depths: [3, 3, 3]
      up_depths: [3, 3]
  connector:
    target: rqvae.models.connectors.ReshapeAndSplit_connector
    params:
      split: 1
      remove_cls: true
  stage_2:
    target: rqvae.models.DiT.DiT_Stage2
    params:
      # DiT B/1 Recipe
      hidden_size: 1152
      input_size: 16
      patch_size: 1
      depth: 28
      num_heads: 16
      num_classes: 1000
      cfg: 0.0
      in_channels: 32
      learn_sigma: true
      noise_schedule: 'linear'
      inference_step: 250
  checkpointing: false
  ema: 0.9999
  ckpt_path: './ckpt_gcs/mae_width/d32_h8_convnext/d32_b4096_lr16e-4_h8_DCAEConvNext_29102024_185426/ep_50-checkpoint/0-model.pt'
optimizer:
  # Original VQ-GAN: lr = 4.5e-06 * (batch size) -> 5.4e-5 for batch size 12
  type: adamw
  init_lr: 1.0e-4
  weight_decay: 0.0
  betas: [0.9, 0.999]
  max_gn: None
  amp: true
  warmup:
    epoch: 80
    multiplier: 1
    buffer_epoch: 0
    min_lr: 1.0e-4
    mode: fix
    start_from_zero: false

experiment:
  batch_size: 32
  accu_step: 1
  epochs: 80
  save_ckpt_freq: 40
  test_freq: 10
  amp: false
  actual_batch_size: 256